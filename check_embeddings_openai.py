import os
from openai import OpenAI
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

def test_openai_embedding():
    print("ğŸ§ª Probando Embeddings con OpenAI (Modelo text-embedding-3-small)...")
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ Error: Falta OPENAI_API_KEY en el archivo .env")
        print("â„¹ï¸  Agrega: OPENAI_API_KEY=sk-...")
        return

    # Cliente especÃ­fico para OpenAI (separado de DeepSeek)
    client = OpenAI(api_key=api_key)

    try:
        text = "El caos es el orden aÃºn no descifrado."
        
        # Llamada estÃ¡ndar a OpenAI
        response = client.embeddings.create(
            input=text,
            model="text-embedding-3-small"
        )
        
        vector = response.data[0].embedding
        dim = len(vector)
        
        print("\nâœ… Â¡Ã‰XITO! OpenAI generÃ³ el vector.")
        print(f"ğŸ“Š DimensiÃ³n: {dim}")
        
        if dim == 1536:
            print("ğŸŸ¢ COMPATIBLE: Coincide perfectamente con tu tabla Postgres (VECTOR(1536)).")
            print("   Podemos proceder a ensamblar el sistema hÃ­brido.")
        else:
            print(f"âš ï¸ DIFIERE: La tabla espera 1536, recibimos {dim}.")

    except Exception as e:
        print(f"\nâŒ FALLO: {e}")

if __name__ == "__main__":
    test_openai_embedding()